# Shadow AI Model Configuration

# Model Architecture
model:
  name: "hybrid_cnn"
  input_shape_bvp: [3840, 1]  # 60-second BVP segment at 64Hz
  input_shape_features: [19]   # HRV features
  num_classes: 4               # Baseline, Stress, Amusement, Meditation
  
  # CNN Branch (BVP processing)
  cnn_branch:
    filters: [16, 32, 16]     # Number of filters per layer
    kernel_sizes: [8, 16, 8]  # Kernel sizes
    pool_sizes: [4, 4, 4]     # Pooling sizes
    dropout_rate: 0.3
    
  # Dense Branch (HRV features)
  dense_branch:
    units: [64, 32]           # Hidden layer units
    dropout_rate: 0.2
    
  # Combined layers
  combined:
    units: [128, 64]          # Units after concatenation
    dropout_rate: 0.3

# Training Parameters
training:
  batch_size: 500
  epochs: 200
  learning_rate: 0.001
  optimizer: "adam"
  loss_function: "categorical_crossentropy"
  
  # Early stopping
  early_stopping:
    patience: 20
    min_delta: 0.001
    restore_best_weights: true
    
  # Validation
  validation_split: 0.2
  cross_validation: "loso"    # Leave-One-Subject-Out
  
  # Callbacks
  callbacks:
    - "early_stopping"
    - "model_checkpoint"
    - "reduce_lr_on_plateau"
    - "tensorboard"

# Data Processing
data:
  # BVP Processing
  bvp:
    sampling_rate: 64         # Hz
    window_size: 60           # seconds
    overlap: 5                # seconds
    filter_low: 0.7           # Hz
    filter_high: 3.7          # Hz
    filter_order: 3
    
  # Feature Extraction
  features:
    hrv_features: true
    frequency_features: true
    statistical_features: true
    
  # Normalization
  normalization:
    method: "z_score"         # z_score, min_max, robust
    fit_on_train: true

# TinyML Deployment
deployment:
  target_device: "esp32_s3"
  quantization:
    enabled: true
    method: "post_training"
    representative_dataset_size: 1000
    
  # Model optimization
  optimization:
    enable_pruning: false
    target_size_kb: 100       # Target model size
    enable_fusion: true
    
  # ESP32 specific
  esp32:
    max_ram_kb: 512
    max_flash_kb: 4096
    inference_time_ms: 100    # Target inference time

# Logging and Results
logging:
  log_level: "INFO"
  save_plots: true
  save_metrics: true
  tensorboard_logs: true
  
results:
  save_dir: "results/"
  model_format: ["h5", "tflite"]
  save_best_only: true
