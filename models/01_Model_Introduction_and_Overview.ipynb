{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashiduDissanayake/Shadow/blob/main/Shadow_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIuTE6z-ZXIx"
      },
      "source": [
        "# Shadow AI Stress Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2f797b03"
      },
      "source": [
        "Shadow AI is an open-source, privacy-focused digital wellness platform designed for solo professionals. It collects data from your devices (laptop, Android phone, wristband) and processes it locally, ensuring your data remains under your control. Shadow provides personalized insights for stress management, health monitoring, sleep optimization, and productivity enhancement without relying on cloud servers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a88e28bf"
      },
      "source": [
        "# Project Plan: Shadow AI Stress Detection\n",
        "\n",
        "This plan outlines the steps to build and deploy a stress detection model using the WESAD dataset, with a focus on preparing it for TinyML deployment on an ESP32-S3 microcontroller.\n",
        "\n",
        "## Phase 1: Build & Validate the Model on PC (Colab)\n",
        "\n",
        "This phase focuses on developing and testing the stress detection model in a Colab environment.\n",
        "\n",
        "### 1.1 Understand the Dataset (WESAD)\n",
        "\n",
        "*   **Dataset Description:** WESAD (Wearable Stress and Affect Detection) is a publicly available dataset for stress detection research.\n",
        "*   **Data Modalities:** The dataset includes data from a wrist-worn device, specifically:\n",
        "    *   BVP (Blood Volume Pulse)\n",
        "    *   EDA (Electrodermal Activity)\n",
        "    *   TEMP (Temperature)\n",
        "    *   ACC (Accelerometer)\n",
        "*   **Focus for First Version:** For the initial version, we will use only the **BVP** modality, similar to the approach in the referenced paper.\n",
        "\n",
        "### 1.2 Preprocessing Pipeline\n",
        "\n",
        "This step involves preparing the BVP data for model training.\n",
        "\n",
        "*   **Filtering:** Apply a Butterworth filter of order 3 with a frequency range of 0.7–3.7 Hz to the BVP data.\n",
        "*   **Segmentation:** Divide the filtered BVP data into 60-second windows with a 5-second overlap. At a sampling rate of 64 Hz, this will result in 3840 samples per segment.\n",
        "*   **Feature Extraction:** Extract Heart Rate Variability (HRV) statistics and frequency-domain HRV metrics from each segment.\n",
        "*   **Normalization:** Apply z-score normalization to the extracted features.\n",
        "\n",
        "### 1.3 Implement the Hybrid CNN (H-CNN) in Colab\n",
        "\n",
        "This step involves building the model architecture in Colab, keeping in mind the constraints for TinyML deployment.\n",
        "\n",
        "*   **Model Architecture:** Implement the Hybrid CNN (H-CNN) as described in the PDF and your requirements:\n",
        "    *   **Input 1:** Takes the 3840x1 BVP segment.\n",
        "    *   **CNN Branch:** Consists of convolutional blocks, pooling layers, and dropout layers.\n",
        "    *   **Input 2:** Takes the 19 extracted HRV features.\n",
        "    *   **Dense Layer for Input 2:** Processes the HRV features.\n",
        "    *   **Concatenation Layer:** Combines the outputs from the CNN branch and the Dense layer for Input 2.\n",
        "    *   **Final Layers:** Includes subsequent Dense layer(s) and a final Softmax layer for classification.\n",
        "*   **MCU Compatibility Tips:** When implementing the model, consider these points for later deployment on ESP32-S3:\n",
        "    *   Use 1D convolutional filters with 8–32 filters (avoid 64+).\n",
        "    *   Keep kernel sizes small (3–16).\n",
        "    *   Aim for a total parameter count of less than ~100k if possible.\n",
        "    *   Avoid computationally heavy layers like LSTMs in the first version.\n",
        "\n",
        "### 1.4 Train and Validate the Model\n",
        "\n",
        "This step involves training the H-CNN model and evaluating its performance.\n",
        "\n",
        "*   **Training Parameters:**\n",
        "    *   **Loss Function:** CategoricalCrossentropy\n",
        "    *   **Optimizer:** Adam with a learning rate of 0.001\n",
        "    *   **Batch Size:** 500\n",
        "    *   **Epochs:** 200\n",
        "    *   **Early Stopping:** Implement early stopping based on predefined criteria to prevent overfitting.\n",
        "*   **Validation Strategy:** Use Leave-One-Subject-Out (LOSO) cross-validation to evaluate the model's generalization ability.\n",
        "*   **Output:** Save the best-performing model as a `.h5` file.\n",
        "\n",
        "## Phase 2: Prepare for TinyML Deployment\n",
        "\n",
        "This phase focuses on converting and optimizing the trained model for resource-constrained microcontrollers.\n",
        "\n",
        "*   **Model Conversion:** Convert the Keras/TensorFlow model (`.h5`) to a format suitable for TinyML, such as TensorFlow Lite for Microcontrollers (TFLite Micro).\n",
        "*   **Quantization:** Explore and apply quantization strategies (e.g., post-training quantization) to reduce the model size and computational requirements.\n",
        "*   **Model Optimization:** Perform any further optimizations needed to ensure the model runs efficiently on the target hardware (ESP32-S3).\n",
        "\n",
        "## Phase 3: Deploy to ESP32-S3\n",
        "\n",
        "This phase covers the steps for integrating and running the model on the ESP32-S3 microcontroller.\n",
        "\n",
        "*   **Environment Setup:** Set up the development environment for ESP32-S3 and TFLite Micro.\n",
        "*   **Model Integration:** Integrate the converted and quantized model into the ESP32-S3 project.\n",
        "*   **Data Acquisition on ESP32-S3:** Implement the logic to acquire BVP data from the wristband on the ESP32-S3.\n",
        "*   **On-Device Preprocessing:** Implement the preprocessing pipeline (filtering, segmentation, feature extraction, normalization) directly on the ESP32-S3.\n",
        "*   **Inference:** Run the TinyML model on the preprocessed data on the ESP32-S3 to obtain stress predictions.\n",
        "*   **Output Handling:** Define how the model's output (stress prediction) will be handled or communicated by the ESP32-S3 (e.g., via a display, LED, or wireless communication).\n",
        "\n",
        "## Phase 4: Optimize & Personalize\n",
        "\n",
        "This phase outlines potential future enhancements and refinements.\n",
        "\n",
        "*   **Optimization:** Continuously optimize the model and the entire processing pipeline for improved performance, lower power consumption, or reduced memory usage on the ESP32-S3.\n",
        "*   **Personalization:** Explore strategies for personalizing the model for individual users over time to improve accuracy.\n",
        "*   **Integration of Other Modalities:** Consider incorporating other WESAD modalities (EDA, TEMP, ACC) in future versions to potentially improve stress detection accuracy.\n",
        "*   **User Interface/Feedback:** Develop a method to communicate the stress detection results to the user, possibly through a connected phone application.\n",
        "\n",
        "## Finish Task\n",
        "\n",
        "*   Review the generated outline for clarity and completeness, ensuring it accurately reflects the project phases and incorporates details from the provided context and PDF."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPrt/P7Qz3Y/39rpvFgA1dx",
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
